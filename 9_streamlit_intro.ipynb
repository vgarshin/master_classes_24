{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e4caf1-c209-46ed-aadd-ca9895509870",
   "metadata": {},
   "source": [
    "# Mastering Applied Skills in Management, Analytics and Entrepreneurship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a90c2-50f7-43d6-8458-87b83e52e288",
   "metadata": {},
   "source": [
    "## DATA COLLECTION TECHNIQUES\n",
    "## Part IX. What to do with the data collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f9b03-40c5-4b4d-a530-150ac9be8ac4",
   "metadata": {},
   "source": [
    "### 1. About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d643f3-8936-4d8d-a7e8-f438a65ea7ed",
   "metadata": {},
   "source": [
    "We have collected some data but what is next? Here we will try to apply a framework that will help us to build a small application based on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04217bb0-3144-443f-a9f6-c7f92a7d26b9",
   "metadata": {},
   "source": [
    "[Streamlit](https://streamlit.io/) is a framework that offers a faster way to build and share data applications. It helps you to turn data scripts into shareable web apps in minutes. It is written in pure Python and does not require front‑end experience to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace9f05-e09a-4c3f-8c05-3cc3e32f0620",
   "metadata": {},
   "source": [
    "### 2. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b49d2c-95e3-4030-8358-66cc5c970c74",
   "metadata": {},
   "source": [
    "Installation is very simple in our environment. Just use terminal or type here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bb1f7-311f-4021-8540-ac1b4da2694a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d1367-0a9e-4f7c-bb8f-b798ce52d5a6",
   "metadata": {},
   "source": [
    "### 3. How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb7058-ad37-458b-b278-044806419a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Main concepts](https://docs.streamlit.io/library/get-started/main-concepts) require you to create a normal Python script with all necessary elements for your future app and run it with `streamlit run` like `streamlit run your_script.py [-- script args]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e1028-ada6-46e6-85e9-002086c6f6f7",
   "metadata": {},
   "source": [
    "#### 3.1. Python script with app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa5935-7b74-4b17-b664-7113b6d8a469",
   "metadata": {},
   "source": [
    "Streamlit's architecture allows you to write apps the same way you write plain Python scripts. Let's create the sample script with `%%writefile` magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3877b6c-2817-4f68-8825-419a8f8a99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Title of our demo app\n",
    "st.title('Meet the first Streamlit application')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74095332-886b-4cda-8169-a0642cd53aab",
   "metadata": {},
   "source": [
    "#### 3.2. Run application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d23de-7527-44bb-a4ff-a505f7fa7acb",
   "metadata": {},
   "source": [
    "Run application is very easy. Just open a terminal and type `streamlit run manutils/stapp.py` or use Jupyter interface like shown below. Note, that we need to find a proper URL to open Streamlit application within Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a8d08-7a4e-4c89-8f7f-f653c56eaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better use port's value in range\n",
    "# from 1000 (or even 10000) to 64000\n",
    "\n",
    "PORT = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896921c-60a8-444d-a1aa-278aa051387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run stapp.py --server.port {PORT} --browser.gatherUsageStats False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951f3ce-28a5-45a9-ac31-e04fbbe002a5",
   "metadata": {},
   "source": [
    "We are in our oun JupyterHub environment and the urls above will not work. To get the application's interface we need some trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f7d88-26cf-4b11-acc1-2735fbeb6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb156d46-3d86-470a-80f6-e37ffc38d1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Streamlit available at:',\n",
    "      'https://jhas01.gsom.spbu.ru{}proxy/{}/'.format(\n",
    "          os.environ['JUPYTERHUB_SERVICE_PREFIX'], PORT))\n",
    "\n",
    "!streamlit run stapp.py --server.port {PORT} --browser.gatherUsageStats False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498d5c1-a3fb-4050-bc78-b102d8668511",
   "metadata": {},
   "source": [
    "### 4. Basic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c63dd-c203-4952-ad67-f29d478a9d43",
   "metadata": {},
   "source": [
    "#### 4.1. Nice headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd66dbb-36fa-433d-829c-9a87340dd160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Nice looking header string', divider='rainbow')\n",
    "st.header('_Here is header under the line_ :fire:')\n",
    "\n",
    "st.subheader('Subheader is also here', divider='rainbow')\n",
    "st.subheader(':blue[_We like Streamlit_] :star:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb65cc-d528-48fe-9905-5eab89d38ab8",
   "metadata": {},
   "source": [
    "#### 4.2. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334000c-10bb-449c-a2f7-9b1bdf6dda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Just header', divider='rainbow')\n",
    "st.text('Just text under the header')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f29cf-9af2-4687-a3fd-8639e809c3f4",
   "metadata": {},
   "source": [
    "#### 4.3. Write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d83f88-dad4-477a-a817-23bf578f7fe3",
   "metadata": {},
   "source": [
    "Along with magic commands, `st.write()` is Streamlit's \"Swiss Army knife\". You can pass almost anything to `st.write()`: text, data, Matplotlib figures, charts and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78e41a-3d1d-4827-ba26-e06a78a97a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.header('Demo of write function', divider='rainbow')\n",
    "\n",
    "st.write(\"Here's demo table from the dataframe:\")\n",
    "fruits_data = pd.DataFrame(\n",
    "    {\n",
    "        'fruits': ['apple', 'peach', 'pineapple', 'watermelon'],\n",
    "        'color': ['green', 'orange', 'yellow', 'stripes'],\n",
    "        'weight': [1, 2, 5, 10]\n",
    "    }\n",
    ")\n",
    "st.write(fruits_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fbd00-8d22-4b2e-9adc-e5b72090108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "st.header('Demo of write function', divider='rainbow')\n",
    "st.subheader('Table and plot at one application')\n",
    "\n",
    "st.divider()\n",
    "\n",
    "st.write(\"Here's demo table from the dataframe:\")\n",
    "fruits_data = pd.DataFrame(\n",
    "    {\n",
    "        'fruits': ['apple', 'peach', 'pineapple', 'watermelon'],\n",
    "        'color': ['green', 'orange', 'yellow', 'stripes'],\n",
    "        'weight': [1, 2, 5, 10]\n",
    "    }\n",
    ")\n",
    "st.write(fruits_data)\n",
    "\n",
    "st.divider()\n",
    "\n",
    "st.write(\"Here's demo chart for fruits:\")\n",
    "chart_data = pd.DataFrame(\n",
    "     np.random.randn(20, 4),\n",
    "     columns=['apple', 'peach', 'pineapple', 'watermelon']\n",
    ")\n",
    "st.line_chart(chart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccde3d-f9a5-4ac6-bbdd-faa65c5d82b9",
   "metadata": {},
   "source": [
    "#### 4.4. Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4c73a-d8a4-42a7-b660-59eb71232df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba21fa0-e26b-4fa9-8bf9-f535382e1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url_loc = 'http://api.open-notify.org/iss-now.json'\n",
    "n_points = 10\n",
    "positions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08b50e-b904-4ef5-9e20-a47fa2903c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(n_points):\n",
    "    response = requests.get(api_url_loc)\n",
    "    d = response.json()\n",
    "    uts = d['timestamp']\n",
    "    d['timestamp'] = datetime.utcfromtimestamp(uts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    positions.append(d)\n",
    "    print(p, 'uts time collected:', d['timestamp'])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81294c59-6b6e-40f3-84b5-49de990949a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [\n",
    "    (float(x['iss_position']['latitude']), float(x['iss_position']['longitude']))\n",
    "    for x in positions\n",
    "]\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404155a3-3817-4ea0-a50c-b9354285b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    coords,\n",
    "    columns=['lat', 'lon']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe79a3-15a6-4ddd-b927-4f1cf6795837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "\n",
    "st.header('ISS over Earth', divider='rainbow')\n",
    "\n",
    "st.write('Demo of ISS coordinates over the time on a map:')\n",
    "         \n",
    "api_url_loc = 'http://api.open-notify.org/iss-now.json'\n",
    "n_points = 10\n",
    "positions = []\n",
    "for p in range(n_points):\n",
    "    response = requests.get(api_url_loc)\n",
    "    d = response.json()\n",
    "    uts = d['timestamp']\n",
    "    d['timestamp'] = datetime.utcfromtimestamp(uts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    positions.append(d)\n",
    "    time.sleep(1)\n",
    "coords = [\n",
    "    (float(x['iss_position']['latitude']), float(x['iss_position']['longitude']))\n",
    "    for x in positions\n",
    "]\n",
    "map_data = pd.DataFrame(\n",
    "    coords,\n",
    "    columns=['lat', 'lon']\n",
    ")\n",
    "st.map(map_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b839c8-30b1-4209-aa06-21928ceaf80b",
   "metadata": {},
   "source": [
    "## <font color='red'>INTERMEDIATE QUIZ #9-1</font>\n",
    "Take the code below and add a table with ISS crew members before map with ISS trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e65b9f-b13f-4696-a082-a9e5779a3cf9",
   "metadata": {},
   "source": [
    "#### HINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1646cf9-be4f-4987-bd81-0d4cb467476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "\n",
    "st.header('ISS over Earth', divider='rainbow')\n",
    "\n",
    "st.write('ISS crew:')\n",
    "api_url_crew = 'http://api.open-notify.org/astros.json'\n",
    "################\n",
    "# YOUR CODE HERE\n",
    "################\n",
    "\n",
    "st.divider()\n",
    "\n",
    "st.write('Demo of ISS coordinates over the time on a map:')\n",
    "\n",
    "api_url_loc = 'http://api.open-notify.org/iss-now.json'\n",
    "n_points = 10\n",
    "positions = []\n",
    "for p in range(n_points):\n",
    "    response = requests.get(api_url_loc)\n",
    "    d = response.json()\n",
    "    uts = d['timestamp']\n",
    "    d['timestamp'] = datetime.utcfromtimestamp(uts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    positions.append(d)\n",
    "    time.sleep(1)\n",
    "coords = [\n",
    "    (float(x['iss_position']['latitude']), float(x['iss_position']['longitude']))\n",
    "    for x in positions\n",
    "]\n",
    "map_data = pd.DataFrame(\n",
    "    coords,\n",
    "    columns=['lat', 'lon']\n",
    ")\n",
    "st.map(map_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a1fdd-852e-4806-837a-4c5c14e348fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Advanced tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c0df3-6d4a-4145-9103-32d9ef8cb57e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.1. Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2331461-f54f-4981-ae22-681beb82644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "name = st.chat_input('What is ypour name?')\n",
    "if name:\n",
    "    st.write(f'Hello, {name}!')\n",
    "else:\n",
    "    st.write('My name is Streamlit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83c628-4bb6-45cb-9a80-a562187691d7",
   "metadata": {},
   "source": [
    "#### 5.2. Censor chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66f9dc-b711-4e49-95ac-b37a16747683",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import re\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Chat that hates f-words', divider='rainbow')\n",
    "\n",
    "def repl(m): \n",
    "    return '<CENZORED(' + str(len(m[0])) + ')>' \n",
    "\n",
    "# Initialize chat history with help of `st.session_state`\n",
    "# https://docs.streamlit.io/library/api-reference/session-state\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat messages from history on app rerun\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message['role']):\n",
    "        st.markdown(message['content'])\n",
    "\n",
    "# React to user input\n",
    "# NOTE walrus operator in Python\n",
    "# https://docs.python.org/3/whatsnew/3.8.html\n",
    "if msg := st.chat_input('Enter your message'):\n",
    "    # Display user's message in chat message container\n",
    "    st.chat_message('user').markdown(msg)\n",
    "    # Add user's message to chat history\n",
    "    st.session_state.messages.append({'role': 'user', 'content': msg})\n",
    "    \n",
    "    # Censor filter with RE\n",
    "    msg = re.sub(r'\\b[fF]\\w*', repl, msg)\n",
    "    \n",
    "    answer = f'Censored: {msg}'\n",
    "    # Display assistant response in chat message container\n",
    "    with st.chat_message('assistant'):\n",
    "        st.markdown(answer)\n",
    "    # Add assistant response to chat history\n",
    "    st.session_state.messages.append({'role': 'assistant', 'content': answer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d1cc1-1541-41e4-9a89-c47a6c14479f",
   "metadata": {},
   "source": [
    "#### 5.3. Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a03321-fe97-440a-9866-6869349dda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'fruits': ['apple', 'peach', 'pineapple', 'watermelon'],\n",
    "        'weight': [1, 2, 5, 10]\n",
    "    }\n",
    ")\n",
    "df = df.set_index('fruits')\n",
    "st.write(df)\n",
    "st.bar_chart(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44c6a4-2624-468b-a929-6324b5993b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Streamlit available at:',\n",
    "      'https://jhas01.gsom.spbu.ru{}proxy/{}/'.format(\n",
    "          os.environ['JUPYTERHUB_SERVICE_PREFIX'], PORT))\n",
    "\n",
    "!streamlit run stapp.py --server.port {PORT} --browser.gatherUsageStats False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9cbe0-6b7a-4673-b7ad-a488299f2e96",
   "metadata": {},
   "source": [
    "##### 5.3.1. Site analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e22c48-b1e8-44b0-8045-da337feb6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Internet sites word analyzer', divider='rainbow')\n",
    "\n",
    "url = st.text_input('Input URL', '')\n",
    "if url:\n",
    "    st.write('The URL for analysis is', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1f08c-eb93-4961-8aa8-f039de6cfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Internet sites word analyzer', divider='rainbow')\n",
    "\n",
    "url = st.text_input('Input URL', '')\n",
    "if url:\n",
    "    st.write('The URL for analysis is', url)\n",
    "    \n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    text = soup.text\n",
    "    for ch in ['\\n', '\\t', '\\r']:\n",
    "        text = text.replace(ch, ' ')\n",
    "    text = re.sub('[^а-яА-Яa-zA-Z]+', ' ', text).strip().lower()\n",
    "    \n",
    "    freqs = dict(Counter(text.split()))\n",
    "    freqs = dict(sorted(\n",
    "        freqs.items(), \n",
    "        key=lambda item: item[1], \n",
    "        reverse=True\n",
    "    ))\n",
    "    limit = 10\n",
    "    freqs = [(k, v) for k, v in freqs.items() if v >= limit]\n",
    "    df = pd.DataFrame(\n",
    "        freqs,\n",
    "        columns=['word', 'count']\n",
    "    )\n",
    "    \n",
    "    st.divider()\n",
    "    st.write(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cf34f-b972-44c1-90a0-39407b416d7b",
   "metadata": {},
   "source": [
    "##### 5.3.2. Site analyzer with limit and more pythonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca40edd-1e87-4618-b0db-a32fe8b38b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "\n",
    "def soup_from_url(url):\n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def text_proc(soup):\n",
    "    text = soup.text\n",
    "    for ch in ['\\n', '\\t', '\\r']:\n",
    "        text = text.replace(ch, ' ')\n",
    "    text = re.sub('[^а-яА-Яa-zA-Z]+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def df_lim(text, limit=1):\n",
    "    freqs = dict(Counter(text.split()))\n",
    "    freqs = dict(sorted(\n",
    "        freqs.items(), \n",
    "        key=lambda item: item[1], \n",
    "        reverse=True\n",
    "    ))\n",
    "    freqs = [(k, v) for k, v in freqs.items() if v >= limit]\n",
    "    df = pd.DataFrame(\n",
    "        freqs,\n",
    "        columns=['word', 'count']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "st.header('Internet sites word analyzer', divider='rainbow')\n",
    "\n",
    "url = st.text_input('Input URL', '')\n",
    "if url:\n",
    "    st.write('The URL for analysis is', url)\n",
    "    limit = st.slider('Select lower word count limit', 0, 100, 1)\n",
    "    \n",
    "    # processing part\n",
    "    soup = soup_from_url(url)\n",
    "    text = text_proc(soup)\n",
    "    df = df_lim(text, limit)\n",
    "    \n",
    "    # output part\n",
    "    st.divider()\n",
    "    st.write(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39cdce-c63b-4581-9708-cd648e14b431",
   "metadata": {},
   "source": [
    "##### 5.3.3. Site analyzer with diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6573c-dbc4-42f1-aade-cc28f8b311e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "\n",
    "def soup_from_url(url):\n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def text_proc(soup):\n",
    "    text = soup.text\n",
    "    for ch in ['\\n', '\\t', '\\r']:\n",
    "        text = text.replace(ch, ' ')\n",
    "    text = re.sub('[^а-яА-Яa-zA-Z]+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def df_lim(text, limit=1):\n",
    "    freqs = dict(Counter(text.split()))\n",
    "    freqs = dict(sorted(\n",
    "        freqs.items(), \n",
    "        key=lambda item: item[1], \n",
    "        reverse=True\n",
    "    ))\n",
    "    freqs = [(k, v) for k, v in freqs.items() if v >= limit]\n",
    "    df = pd.DataFrame(\n",
    "        freqs,\n",
    "        columns=['word', 'count']\n",
    "    )\n",
    "    df = df.set_index('word')\n",
    "    return df\n",
    "\n",
    "st.header('Internet sites word analyzer', divider='rainbow')\n",
    "\n",
    "url = st.text_input('Input URL', '')\n",
    "if url:\n",
    "    st.write('The URL for analysis is', url)\n",
    "    limit = st.slider('Select lower word count limit', 0, 100, 1)\n",
    "    \n",
    "    # processing part\n",
    "    soup = soup_from_url(url)\n",
    "    text = text_proc(soup)\n",
    "    df = df_lim(text, limit)\n",
    "    \n",
    "    # table output part\n",
    "    st.divider()\n",
    "    st.write('Top-5 words from the site')\n",
    "    st.write(df.head(5))\n",
    "    \n",
    "    # plot output part\n",
    "    st.divider()\n",
    "    st.write('Words from the site')\n",
    "    st.bar_chart(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf8077-d8a4-4b11-94f9-4b95adc6dce3",
   "metadata": {},
   "source": [
    "## <font color='red'>LAB WORK #6</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a5d5-9815-4710-a8f5-bbba115d624e",
   "metadata": {},
   "source": [
    "We built a nice analyzer but it seems that we need to make upper limit for words count as well. So, your home assignment will be to update code with the lower limit and get the new Streamlit app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdb948-9feb-4284-b034-c3a030e2fa3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### HINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494e5b5-ffeb-40d5-9571-7f4309332113",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "\n",
    "low_limit, upp_limit = st.slider(\n",
    "    'Select limits',\n",
    "    0, 100, (10, 90)\n",
    ")\n",
    "st.write('Lower limit:', low_limit)\n",
    "st.write('Lower limit:', upp_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c26cd6-f9d4-4490-af05-bbab6ae3e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will also need to change a function `df_lim`\n",
    "# for example like that\n",
    "\n",
    "def df_lim(text, low_limit, upp_limit):\n",
    "    freqs = dict(Counter(text.split()))\n",
    "    freqs = dict(sorted(\n",
    "        freqs.items(), \n",
    "        key=lambda item: item[1], \n",
    "        reverse=True\n",
    "    ))\n",
    "    freqs = ### YOUR CODE HERE ####\n",
    "    df = pd.DataFrame(\n",
    "        freqs,\n",
    "        columns=['word', 'count']\n",
    "    )\n",
    "    df = df.set_index('word')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78889b0e-e7a7-47a2-bc7b-450217f431f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
